{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album</th>\n",
       "      <th>Text_lenght</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Eminem]\\nPeace to Thirstin Howl, A.L. and Word...</td>\n",
       "      <td>eminem and dilated peoples freestyle</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>2156</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nI reckon you ain't familiar with these here ...</td>\n",
       "      <td>bad meets evil</td>\n",
       "      <td>The Slim Shady LP</td>\n",
       "      <td>4064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nLately I've been hard to reach\\nI've been to...</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>Relapse</td>\n",
       "      <td>4927</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nEminem\\nMiscellaneous\\nB-Rabbit Vs. Papa Doc...</td>\n",
       "      <td>b rabbit vs papa doc freestyle from 8 mile</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>1646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\nEminem\\nMiscellaneous\\nEminem Exclusive Free...</td>\n",
       "      <td>eminem exclusive freestyle</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>1244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   ...      Year\n",
       "0           0   ...       NaN\n",
       "1           1   ...       NaN\n",
       "2           2   ...    2009.0\n",
       "3           3   ...       NaN\n",
       "4           4   ...       NaN\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = pd.read_csv('../input/eminem.csv')\n",
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "04ad4a60d8e894fe524bcb0f581d709e7f491e79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Eminem]\\nPeace to Thirstin Howl, A.L. and Word...\n",
       "1    \\nI reckon you ain't familiar with these here ...\n",
       "2    \\nLately I've been hard to reach\\nI've been to...\n",
       "3    \\nEminem\\nMiscellaneous\\nB-Rabbit Vs. Papa Doc...\n",
       "4    \\nEminem\\nMiscellaneous\\nEminem Exclusive Free...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_text = lyrics['text']\n",
    "lyrics_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "057884a2dbfb29421c6bdced99c37889a0dde8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1769150 characters\n"
     ]
    }
   ],
   "source": [
    "text = '\\n\\n'.join(lyrics_text)\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ccd9e1687c4ad73bd23649eee4a96ee9cf21295e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eminem]\n",
      "Peace to Thirstin Howl, A.L. and Wordsworth\n",
      "My mother smoked crack, I had a premature birth\n",
      "I'm just a nerd cursed, wit badly disturbed nerves\n",
      "Who wanna be the one to step up and get served first?\n",
      "Ninety-nine percent of aliens prefer earth\n",
      "So\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4b9eb28b9bd44189236aa761e5b7982cc391257b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7b689a6102aa823caf4cec0e3bad9e1ef017dd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  '$' :   5,\n",
      "  '%' :   6,\n",
      "  '&' :   7,\n",
      "  \"'\" :   8,\n",
      "  '(' :   9,\n",
      "  ')' :  10,\n",
      "  '*' :  11,\n",
      "  '+' :  12,\n",
      "  ',' :  13,\n",
      "  '-' :  14,\n",
      "  '.' :  15,\n",
      "  '/' :  16,\n",
      "  '0' :  17,\n",
      "  '1' :  18,\n",
      "  '2' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "07778c7711270a8e87854004f64ea557c7c6f36f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Eminem]\\nPeace' ---- characters mapped to int ---- > [37 75 71 76 67 75 60  0 48 67 63 65 67]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b58c7ddc5aed0e39f24fc53380eaef3065e646e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "E\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b622508a9c1017868cc131a60672eac8ff1d085c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Eminem]\\nPeace to Thirstin Howl, A.L. and Wordsworth\\nMy mother smoked crack, I had a premature birth\\nI'\n",
      "\"'m just a nerd cursed, wit badly disturbed nerves\\nWho wanna be the one to step up and get served firs\"\n",
      "\"t?\\nNinety-nine percent of aliens prefer earth\\nSo I'm here to rule the planet, startin wit your turf\\nI\"\n",
      "' hid a secret message inside of a wordsearch\\nWit smeard letters, runnin together in blurred spurts\\nI '\n",
      "'hang wit male chauvinist pigs and perverts\\nWho point water pistols at women and squirt shirts\\nBeen a '\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7643c1cf9956cb03d941b475c0251797e884cf63"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "eb62dbc179f1ce4b95f1c42ae4a65deb55e13cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Eminem]\\nPeace to Thirstin Howl, A.L. and Wordsworth\\nMy mother smoked crack, I had a premature birth\\n'\n",
      "Target data: 'minem]\\nPeace to Thirstin Howl, A.L. and Wordsworth\\nMy mother smoked crack, I had a premature birth\\nI'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e7a03ad2b48cd6b6bbf4afb512a8cc47f573b9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 37 ('E')\n",
      "  expected output: 75 ('m')\n",
      "Step    1\n",
      "  input: 75 ('m')\n",
      "  expected output: 71 ('i')\n",
      "Step    2\n",
      "  input: 71 ('i')\n",
      "  expected output: 76 ('n')\n",
      "Step    3\n",
      "  input: 76 ('n')\n",
      "  expected output: 67 ('e')\n",
      "Step    4\n",
      "  input: 67 ('e')\n",
      "  expected output: 75 ('m')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "bdc8eeaea81a1acc209b30ecc4dbf0b172ef5b58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences, \n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "8fd8cd7134f19b6accbae74120bbca597e8d6dc7"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "181e91caa3fadbc441b2338b9c673f234c57c8ff"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "228b884c6c4463f5ba0fb176f2fb9cf2946f93d6"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "fa7ae4854422919b6f0987fb4418f18b9b995fe0"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "550c534b66ddf0e5e39d17ec3443c17565bead24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 111) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5b87eda55ec85c4c010896f10054578f520e9671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           28416     \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 111)           113775    \n",
      "=================================================================\n",
      "Total params: 4,080,495\n",
      "Trainable params: 4,080,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "c610b6a3f8df2887dca3a84e5c5e869eb5fccb44"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c972ca7628746954a2ecdc5a01fd197ce44dc7e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89,  59,  57,  77,  69,  99,  21,  56,  98,  83,  96,  77,  93,\n",
       "        94,  32,  32,  97,  68,   1,  91,  61,  83, 106, 102,  66,  23,\n",
       "        45,  37, 108,  56,  99,  59,  16,  70,  13, 105,  52, 105,  53,\n",
       "        45,  94,  51,  41,  59,  98, 103,  40, 101,  77,  62,  93,  44,\n",
       "        76,  38,  33,  65,  68,  13,  56,  30, 106,  96,  94,   2,  16,\n",
       "         1,  46,  53,  93,  44,  88,  72,   3, 110,  54, 101,  81,  63,\n",
       "        13,  82,  76,  25,  40,  98,  53,  82,  16,  85, 108, 109,  12,\n",
       "        73, 103,  35,  64,  76,  74,  53,  47,  44])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "b36a1c6999ed1195168d21d44116b190f2333f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \" no difficulty multi-taskin' and jugglin' both\\nPerhaps mastered his craft slash entrepreneur\\nWho has\"\n",
      "\n",
      "Next Char Predictions: \n",
      " '{\\\\Yogä4Xâu½o\\xa0©??Ãf ~_u…‘d6ME€Xä\\\\/h,”T”UM©SI\\\\â’H–o`\\xa0LnFAcf,X=…½©!/ NU\\xa0Lzj\"\\ufeffV–sa,tn8HâUt/w€☆+k’CbnlUOL'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "f7da9e4bea4ea3cd37c668c630fa02fe3fb0b066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 111)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.7096953\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "a03bcd450473a496b9b406fba4b480353fcb0a48"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "3d0dd2150b76525c27ff6e18b834d267955265e1"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "63b54e5f426d13fd85add6b24ed326f85d19596c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "275/276 [============================>.] - ETA: 0s - loss: 2.5026WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "276/276 [==============================] - 17s 60ms/step - loss: 2.5006\n",
      "Epoch 2/3\n",
      "276/276 [==============================] - 14s 52ms/step - loss: 1.7937\n",
      "Epoch 3/3\n",
      "276/276 [==============================] - 14s 51ms/step - loss: 1.5491\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=3\n",
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "b9fc7c823a1e512a8039126359d1e97ca446b746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_3'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "5d65f01bd55001bb942530ba347f480c15f31620"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "d33ed74eb6616dd2b8da1e3e8ed02ee89e85f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            28416     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 111)            113775    \n",
      "=================================================================\n",
      "Total params: 4,080,495\n",
      "Trainable params: 4,080,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "e3ebb6ee22bcc5e156bdaf2971b5fdd6591db491"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    \n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "    \n",
    "    # Converting our start string to numbers (vectorizing) \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "    \n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.3\n",
    "    \n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "43521bea9f998e48630b8138ab3bfa3cd156dd58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-c53e82b2833c>:28: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "I'm a double for the same thing\n",
      "\n",
      "What the fuck you to see how they came to say that I was sit back\n",
      "\n",
      "I say I am what you know what the fuck it was so you guess what the fuck you fuckin' shit and she say that you can see her who show\n",
      "\n",
      "I don't know what the fuck down to see the shit down to see (who they can see they call me a start\n",
      "(What?)\n",
      "My name is... (What?) My name is... (HA-HA-HA-HA-HA-HA-HA)\n",
      "Go a little battle who say I am\n",
      "If I was a signed in the party of the man and shit you face and burning in the back of the shit down to see the shit down to see me out when I don't know what the fuck it was a sick that I don't know what the fuck down\n",
      "So I don't know what the fuck it was so bad\n",
      "\n",
      "I'm not a motherfucker you say I am\n",
      "If I was a stand up\n",
      "\n",
      "So where the fuck that I don't know what I don't know what you just a little bit of the shit with a stand up\n",
      "I'm straight of my tear that you fuckin' back\n",
      "\n",
      "So I can't be a little shit the fuck it was trying to see the shit be so who show the shit when I \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"I'm a \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
